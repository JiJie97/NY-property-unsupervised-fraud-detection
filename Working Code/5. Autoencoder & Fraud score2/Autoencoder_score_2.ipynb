{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = z_pca_df.shape[1]\n",
    "encoding_dim = 5\n",
    "hidden_dim = 1\n",
    "learning_rate = 1e-7\n",
    "nb_epoch = 50\n",
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one layer and 5 nodes\n",
    "input_layer = Input(shape = (input_dim,))\n",
    "encoder = Dense(encoding_dim, activation = 'tanh',\n",
    "                activity_regularizer=regularizers.l1(learning_rate))(input_layer)\n",
    "# encoder = Dense(hidden_dim, activation = 'relu')(encoder)\n",
    "# decoder = Dense(hidden_dim,activation = 'tanh')(encoder)\n",
    "decoder = Dense(input_dim,activation = 'relu')(encoder)\n",
    "autoencoder = Model(inputs = input_layer, outputs = decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 5)                 45        \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 8)                 48        \n",
      "=================================================================\n",
      "Total params: 93\n",
      "Trainable params: 93\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9954 - accuracy: 0.5689\n",
      "Epoch 2/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9895 - accuracy: 0.6571\n",
      "Epoch 3/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9864 - accuracy: 0.7248: 1s - loss: 0.7992 - accuracy:  - ETA: 0s - loss: 0.9781  - ETA: 0s - loss: 1.0071 - accuracy: \n",
      "Epoch 4/50\n",
      "1070994/1070994 [==============================] - 2s 1us/step - loss: 0.9840 - accuracy: 0.8064\n",
      "Epoch 5/50\n",
      "1070994/1070994 [==============================] - 2s 1us/step - loss: 0.9821 - accuracy: 0.7921\n",
      "Epoch 6/50\n",
      "1070994/1070994 [==============================] - 2s 1us/step - loss: 0.9802 - accuracy: 0.7713\n",
      "Epoch 7/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9783 - accuracy: 0.7863: 0s - los\n",
      "Epoch 8/50\n",
      "1070994/1070994 [==============================] - 2s 1us/step - loss: 0.9765 - accuracy: 0.6587\n",
      "Epoch 9/50\n",
      "1070994/1070994 [==============================] - 2s 1us/step - loss: 0.9748 - accuracy: 0.6646\n",
      "Epoch 10/50\n",
      "1070994/1070994 [==============================] - 2s 1us/step - loss: 0.9732 - accuracy: 0.6622\n",
      "Epoch 11/50\n",
      "1070994/1070994 [==============================] - 2s 1us/step - loss: 0.9718 - accuracy: 0.6584: 0s - loss: 0.8530 \n",
      "Epoch 12/50\n",
      "1070994/1070994 [==============================] - 2s 1us/step - loss: 0.9704 - accuracy: 0.6592: 0s - loss: 0.9882 \n",
      "Epoch 13/50\n",
      "1070994/1070994 [==============================] - 2s 1us/step - loss: 0.9689 - accuracy: 0.6553: 0s - loss: 1.1452 - \n",
      "Epoch 14/50\n",
      "1070994/1070994 [==============================] - 2s 1us/step - loss: 0.9677 - accuracy: 0.6514\n",
      "Epoch 15/50\n",
      "1070994/1070994 [==============================] - ETA: 0s - loss: 0.9729 - accuracy: 0.65 - 2s 1us/step - loss: 0.9664 - accuracy: 0.6519\n",
      "Epoch 16/50\n",
      "1070994/1070994 [==============================] - 2s 1us/step - loss: 0.9653 - accuracy: 0.6468: 0s\n",
      "Epoch 17/50\n",
      "1070994/1070994 [==============================] - 2s 1us/step - loss: 0.9639 - accuracy: 0.6473\n",
      "Epoch 18/50\n",
      "1070994/1070994 [==============================] - 2s 1us/step - loss: 0.9628 - accuracy: 0.6423\n",
      "Epoch 19/50\n",
      "1070994/1070994 [==============================] - 2s 1us/step - loss: 0.9615 - accuracy: 0.6378\n",
      "Epoch 20/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9603 - accuracy: 0.6358\n",
      "Epoch 21/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9592 - accuracy: 0.6202\n",
      "Epoch 22/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9577 - accuracy: 0.6222: 0s - loss: 0.8237 - accuracy: 0.\n",
      "Epoch 23/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9565 - accuracy: 0.6303\n",
      "Epoch 24/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9552 - accuracy: 0.6525: 0s - loss: 0.9568 - accuracy: 0.65\n",
      "Epoch 25/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9538 - accuracy: 0.6584: 0s - loss: 0.9691 - accuracy: 0.65\n",
      "Epoch 26/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9527 - accuracy: 0.6620TA: 0s - loss: 1.0154 - accuracy: \n",
      "Epoch 27/50\n",
      "1070994/1070994 [==============================] - 2s 1us/step - loss: 0.9517 - accuracy: 0.6643\n",
      "Epoch 28/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9500 - accuracy: 0.6554\n",
      "Epoch 29/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9489 - accuracy: 0.6659\n",
      "Epoch 30/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9476 - accuracy: 0.6663: 0s - loss: 0.6356 - accura - ETA: 0s - loss: 0.7362 - accuracy - ETA: 0s - loss: 0.9 - ETA: 0s - loss: 0.9435 - accuracy: 0.66\n",
      "Epoch 31/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9461 - accuracy: 0.7056: 1s - l - ETA: 0s - loss: 0.9547 \n",
      "Epoch 32/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9440 - accuracy: 0.6849\n",
      "Epoch 33/50\n",
      "1070994/1070994 [==============================] - 2s 1us/step - loss: 0.9426 - accuracy: 0.6970\n",
      "Epoch 34/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9418 - accuracy: 0.7605\n",
      "Epoch 35/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9406 - accuracy: 0.6894\n",
      "Epoch 36/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9397 - accuracy: 0.6458\n",
      "Epoch 37/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9381 - accuracy: 0.6695\n",
      "Epoch 38/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9369 - accuracy: 0.6920: 0s - loss: 0.8875 - accuracy: 0. - ETA: 0s - loss: 0.9102 - accuracy: 0.69\n",
      "Epoch 39/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9359 - accuracy: 0.6920\n",
      "Epoch 40/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9348 - accuracy: 0.6759: 0s - loss: 0.9055 - \n",
      "Epoch 41/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9343 - accuracy: 0.7263\n",
      "Epoch 42/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9338 - accuracy: 0.7400: 0s - loss: 0.9842 - ac\n",
      "Epoch 43/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9326 - accuracy: 0.7251: 0s - loss: 0.9476 - accuracy: 0.\n",
      "Epoch 44/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9312 - accuracy: 0.7081: 0s - loss: 0.913\n",
      "Epoch 45/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9312 - accuracy: 0.7227: 0s - loss:\n",
      "Epoch 46/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9295 - accuracy: 0.7005\n",
      "Epoch 47/50\n",
      "1070994/1070994 [==============================] - 2s 1us/step - loss: 0.9284 - accuracy: 0.7538\n",
      "Epoch 48/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9277 - accuracy: 0.7663\n",
      "Epoch 49/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9269 - accuracy: 0.7923:  - ETA: 0s - loss: 0.890\n",
      "Epoch 50/50\n",
      "1070994/1070994 [==============================] - 2s 2us/step - loss: 0.9259 - accuracy: 0.7099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a786fdda0>"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.compile(metrics = ['accuracy'],\n",
    "                   loss = 'mean_squared_error',\n",
    "                   optimizer = 'adam')\n",
    "# cp = ModelCheckpoint(filepath=\"autoencoder_fraud.h5\",\n",
    "#                                save_best_only=True,\n",
    "#                                verbose=0)\n",
    "\n",
    "# tb = TensorBoard(log_dir='./logs',\n",
    "#                 histogram_freq=0,\n",
    "#                 write_graph=True,\n",
    "#                 write_images=True)\n",
    "\n",
    "autoencoder.fit(z_pca_df, z_pca_df,\n",
    "                     epochs=nb_epoch,\n",
    "                          batch_size=batch_size,\n",
    "                   shuffle=True,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1070994, 8)"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = autoencoder.predict(z_pca_df)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predPCA1</th>\n",
       "      <th>predPCA2</th>\n",
       "      <th>predPCA3</th>\n",
       "      <th>predPCA4</th>\n",
       "      <th>predPCA5</th>\n",
       "      <th>predPCA6</th>\n",
       "      <th>predPCA7</th>\n",
       "      <th>predPCA8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044164</td>\n",
       "      <td>0.028213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029836</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.114280</td>\n",
       "      <td>9.010249</td>\n",
       "      <td>6.900694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024605</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044366</td>\n",
       "      <td>0.033749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008829</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.741181</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.547975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predPCA1  predPCA2  predPCA3  predPCA4  predPCA5   predPCA6  predPCA7  \\\n",
       "0  0.000000  0.000000  0.000000  0.044164  0.028213   0.000000  0.029836   \n",
       "1  4.114280  9.010249  6.900694  0.000000  0.000000   0.000000  0.000000   \n",
       "2  0.000000  0.112350  0.000000  0.024605  0.033500   0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.044366  0.033749   0.000000  0.008829   \n",
       "4  7.741181  0.000000  0.000000  0.000000  0.000000  14.547975  0.000000   \n",
       "\n",
       "   predPCA8  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  "
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame(pred)\n",
    "pred_df.columns = ['predPCA1','predPCA2','predPCA3','predPCA4','predPCA5','predPCA6','predPCA7','predPCA8']\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diff1</th>\n",
       "      <th>diff2</th>\n",
       "      <th>diff3</th>\n",
       "      <th>diff4</th>\n",
       "      <th>diff5</th>\n",
       "      <th>diff6</th>\n",
       "      <th>diff7</th>\n",
       "      <th>diff8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.032383</td>\n",
       "      <td>0.145470</td>\n",
       "      <td>0.125823</td>\n",
       "      <td>0.019353</td>\n",
       "      <td>0.235412</td>\n",
       "      <td>0.054391</td>\n",
       "      <td>0.024626</td>\n",
       "      <td>0.035798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.645210</td>\n",
       "      <td>11.049312</td>\n",
       "      <td>4.075947</td>\n",
       "      <td>3.337183</td>\n",
       "      <td>2.569274</td>\n",
       "      <td>3.095655</td>\n",
       "      <td>2.356457</td>\n",
       "      <td>73.879346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018226</td>\n",
       "      <td>0.017840</td>\n",
       "      <td>0.090244</td>\n",
       "      <td>0.062956</td>\n",
       "      <td>0.017886</td>\n",
       "      <td>0.136472</td>\n",
       "      <td>0.029682</td>\n",
       "      <td>0.603829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.042037</td>\n",
       "      <td>0.094059</td>\n",
       "      <td>0.126849</td>\n",
       "      <td>0.050481</td>\n",
       "      <td>0.109037</td>\n",
       "      <td>0.004066</td>\n",
       "      <td>0.057844</td>\n",
       "      <td>0.171531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.118293</td>\n",
       "      <td>4.655318</td>\n",
       "      <td>2.919147</td>\n",
       "      <td>4.642028</td>\n",
       "      <td>22.393216</td>\n",
       "      <td>4.441082</td>\n",
       "      <td>6.807341</td>\n",
       "      <td>0.722238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      diff1      diff2     diff3     diff4      diff5     diff6     diff7  \\\n",
       "0  0.032383   0.145470  0.125823  0.019353   0.235412  0.054391  0.024626   \n",
       "1  1.645210  11.049312  4.075947  3.337183   2.569274  3.095655  2.356457   \n",
       "2  0.018226   0.017840  0.090244  0.062956   0.017886  0.136472  0.029682   \n",
       "3  0.042037   0.094059  0.126849  0.050481   0.109037  0.004066  0.057844   \n",
       "4  1.118293   4.655318  2.919147  4.642028  22.393216  4.441082  6.807341   \n",
       "\n",
       "       diff8  \n",
       "0   0.035798  \n",
       "1  73.879346  \n",
       "2   0.603829  \n",
       "3   0.171531  \n",
       "4   0.722238  "
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Find the difference between original input records and output records\n",
    "diff = pd.DataFrame()\n",
    "for i in range(8):\n",
    "    diff[i] = abs(z_pca_df.iloc[:,i] - pred_df.iloc[:,i])\n",
    "diff.columns = ['diff1','diff2','diff3','diff4','diff5','diff6','diff7','diff8']\n",
    "diff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = diff**2\n",
    "m2['sum'] = m2.sum(axis = 1)\n",
    "m2['s2'] = m2['sum']**1/2\n",
    "m2 = m2.sort_values('s2',ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diff1</th>\n",
       "      <th>diff2</th>\n",
       "      <th>diff3</th>\n",
       "      <th>diff4</th>\n",
       "      <th>diff5</th>\n",
       "      <th>diff6</th>\n",
       "      <th>diff7</th>\n",
       "      <th>diff8</th>\n",
       "      <th>sum</th>\n",
       "      <th>s2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>632815</th>\n",
       "      <td>260226.159315</td>\n",
       "      <td>201110.027807</td>\n",
       "      <td>322078.159332</td>\n",
       "      <td>197879.901374</td>\n",
       "      <td>18095.494152</td>\n",
       "      <td>13774.339316</td>\n",
       "      <td>9357.417746</td>\n",
       "      <td>16.854663</td>\n",
       "      <td>1.022538e+06</td>\n",
       "      <td>511269.176852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565391</th>\n",
       "      <td>396100.440395</td>\n",
       "      <td>150612.141982</td>\n",
       "      <td>213507.921776</td>\n",
       "      <td>45240.532003</td>\n",
       "      <td>328.518481</td>\n",
       "      <td>36930.837033</td>\n",
       "      <td>5218.685461</td>\n",
       "      <td>3669.948085</td>\n",
       "      <td>8.516090e+05</td>\n",
       "      <td>425804.512608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067359</th>\n",
       "      <td>16198.362081</td>\n",
       "      <td>346129.444002</td>\n",
       "      <td>262922.575213</td>\n",
       "      <td>28507.571015</td>\n",
       "      <td>86.941522</td>\n",
       "      <td>38084.297447</td>\n",
       "      <td>831.319605</td>\n",
       "      <td>138239.257649</td>\n",
       "      <td>8.309998e+05</td>\n",
       "      <td>415499.884267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917941</th>\n",
       "      <td>32606.998978</td>\n",
       "      <td>3872.989418</td>\n",
       "      <td>23752.835776</td>\n",
       "      <td>10130.173201</td>\n",
       "      <td>271538.727078</td>\n",
       "      <td>165479.576915</td>\n",
       "      <td>5421.483573</td>\n",
       "      <td>6806.216013</td>\n",
       "      <td>5.196090e+05</td>\n",
       "      <td>259804.500476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585117</th>\n",
       "      <td>21477.761310</td>\n",
       "      <td>12811.115563</td>\n",
       "      <td>1082.468574</td>\n",
       "      <td>187772.035689</td>\n",
       "      <td>99647.807426</td>\n",
       "      <td>20979.773893</td>\n",
       "      <td>24431.354389</td>\n",
       "      <td>2835.296667</td>\n",
       "      <td>3.710376e+05</td>\n",
       "      <td>185518.806755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67128</th>\n",
       "      <td>39801.266040</td>\n",
       "      <td>2169.931232</td>\n",
       "      <td>3060.099128</td>\n",
       "      <td>789.089239</td>\n",
       "      <td>134273.935087</td>\n",
       "      <td>0.030149</td>\n",
       "      <td>160836.432422</td>\n",
       "      <td>21849.954760</td>\n",
       "      <td>3.627807e+05</td>\n",
       "      <td>181390.369029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585438</th>\n",
       "      <td>16034.561118</td>\n",
       "      <td>9751.441290</td>\n",
       "      <td>5.701324</td>\n",
       "      <td>168130.439074</td>\n",
       "      <td>17200.704577</td>\n",
       "      <td>50580.221163</td>\n",
       "      <td>6910.965990</td>\n",
       "      <td>612.555723</td>\n",
       "      <td>2.692266e+05</td>\n",
       "      <td>134613.295129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565397</th>\n",
       "      <td>51597.910734</td>\n",
       "      <td>12892.555264</td>\n",
       "      <td>14581.901226</td>\n",
       "      <td>1253.677376</td>\n",
       "      <td>9196.218289</td>\n",
       "      <td>60198.600176</td>\n",
       "      <td>115834.061060</td>\n",
       "      <td>2778.763382</td>\n",
       "      <td>2.683337e+05</td>\n",
       "      <td>134166.843753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85885</th>\n",
       "      <td>21582.164803</td>\n",
       "      <td>9393.438948</td>\n",
       "      <td>2726.588657</td>\n",
       "      <td>7932.759587</td>\n",
       "      <td>140190.552743</td>\n",
       "      <td>17268.548522</td>\n",
       "      <td>765.642832</td>\n",
       "      <td>139.750064</td>\n",
       "      <td>1.999994e+05</td>\n",
       "      <td>99999.723078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585119</th>\n",
       "      <td>12139.748607</td>\n",
       "      <td>8155.183895</td>\n",
       "      <td>851.628601</td>\n",
       "      <td>126287.197277</td>\n",
       "      <td>22040.365356</td>\n",
       "      <td>3649.952051</td>\n",
       "      <td>15642.671961</td>\n",
       "      <td>187.183253</td>\n",
       "      <td>1.889539e+05</td>\n",
       "      <td>94476.965501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 diff1          diff2          diff3          diff4  \\\n",
       "632815   260226.159315  201110.027807  322078.159332  197879.901374   \n",
       "565391   396100.440395  150612.141982  213507.921776   45240.532003   \n",
       "1067359   16198.362081  346129.444002  262922.575213   28507.571015   \n",
       "917941    32606.998978    3872.989418   23752.835776   10130.173201   \n",
       "585117    21477.761310   12811.115563    1082.468574  187772.035689   \n",
       "67128     39801.266040    2169.931232    3060.099128     789.089239   \n",
       "585438    16034.561118    9751.441290       5.701324  168130.439074   \n",
       "565397    51597.910734   12892.555264   14581.901226    1253.677376   \n",
       "85885     21582.164803    9393.438948    2726.588657    7932.759587   \n",
       "585119    12139.748607    8155.183895     851.628601  126287.197277   \n",
       "\n",
       "                 diff5          diff6          diff7          diff8  \\\n",
       "632815    18095.494152   13774.339316    9357.417746      16.854663   \n",
       "565391      328.518481   36930.837033    5218.685461    3669.948085   \n",
       "1067359      86.941522   38084.297447     831.319605  138239.257649   \n",
       "917941   271538.727078  165479.576915    5421.483573    6806.216013   \n",
       "585117    99647.807426   20979.773893   24431.354389    2835.296667   \n",
       "67128    134273.935087       0.030149  160836.432422   21849.954760   \n",
       "585438    17200.704577   50580.221163    6910.965990     612.555723   \n",
       "565397     9196.218289   60198.600176  115834.061060    2778.763382   \n",
       "85885    140190.552743   17268.548522     765.642832     139.750064   \n",
       "585119    22040.365356    3649.952051   15642.671961     187.183253   \n",
       "\n",
       "                  sum             s2  \n",
       "632815   1.022538e+06  511269.176852  \n",
       "565391   8.516090e+05  425804.512608  \n",
       "1067359  8.309998e+05  415499.884267  \n",
       "917941   5.196090e+05  259804.500476  \n",
       "585117   3.710376e+05  185518.806755  \n",
       "67128    3.627807e+05  181390.369029  \n",
       "585438   2.692266e+05  134613.295129  \n",
       "565397   2.683337e+05  134166.843753  \n",
       "85885    1.999994e+05   99999.723078  \n",
       "585119   1.889539e+05   94476.965501  "
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(m2['s2'], bins = 50)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
